{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN+g/wadwWI75nITozK8nwB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["شبکه کانولوشنال عمیقی برای پیش‌بینی کلاس‌ها در دیتاست CIFAR10 بسازید. 15 درصد دیتاست را برای تست در نظر بگیرید. عملکرد این شبکه را با بهترین شبکه فصل قبل مقایسه کنید.\n","\n","تعداد لایه‌ها و تعداد و ابعاد کرنل‌های در نظر گرفته شده را گزارش کنید.\n","مدت زمان آموزش شبکه را گزارش کرده و با شبکه Dense فصل قبل مقایسه کنید و accuracy پیش‌بینی را روی داده‌های تست گزارش کنید.\n","عملکرد دو برنامه زمانی Exponential و OneCycle را برای 50 epoch مقایسه کنید.\n","تفاوت حضور و عدم حضور Pooling layer روی شبکه را برای 50 epoch بررسی کنید. مدت زمان آموزش را گزارش کنید و accuracy و loss را نمایش دهید.\n","روی لایه Pooling اثر strideهای 2و 4 را برای 50 epoch بررسی کنید و accuracy و loss را نمایش دهید.\n","همین مسئله را با یکی از شبکه‌های قدرتمندی که در این فصل دیدید حل کنید. یک بار تمام شبکه را فریز کرده و بار دیگر یک لایه از آن را trainable کنید. این مقایسه را برای 50 epoch انجام دهید و accuracy و loss هر دو حالت را در یک گراف نمایش دهید.\n","* قسمت کد پاسخ خود را به صورت لینک Colab یا فایل نوت‌بوک با پسوند .ipynb بفرستید. برای تسریع فرایند تصحیح کد خود را کامنت‌گذاری کنید.\n","\n","* حتما قبل از ارسال کد را اجرا کنید تا نتایج در فایل ارسالی وجود داشته باشد.\n","\n","* قسمت تشریحی پاسخ خود را در یک فایل با فرمت ورد یا پی‌دی‌اف ارسال کنید."],"metadata":{"id":"bGK0wwoVa92c"}},{"cell_type":"markdown","source":["1. تقسیم‌بندی داده‌ها:\n","\n","ابتدا 85 درصد از داده‌ها را برای آموزش و 15 درصد را برای تست جدا می‌کنیم."],"metadata":{"id":"MjSHRnIKbZDh"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kxKBeck6a0d8","executionInfo":{"status":"ok","timestamp":1727106514308,"user_tz":-180,"elapsed":26599,"user":{"displayName":"Sara Soltani","userId":"00129795583987472913"}},"outputId":"735284ba-319c-45e9-ee3c-078b11536900"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 0us/step\n"]}],"source":["from tensorflow.keras.datasets import cifar10\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","\n","# بارگذاری دیتاست CIFAR-10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","# تبدیل برچسب‌ها به one-hot encoding\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# تقسیم داده‌های آموزش به دو بخش: 85% برای آموزش و 15% برای تست\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15, random_state=42)\n"]},{"cell_type":"markdown","source":["2. ساخت شبکه کانولوشنال عمیق (CNN):\n","\n","در این بخش، شبکه CNN با تعدادی لایه کانولوشن و Pooling تعریف می‌شود."],"metadata":{"id":"N9V_V-mYbj7q"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n","\n","# ساخت شبکه کانولوشنال عمیق\n","def create_cnn_model():\n","    model = Sequential([\n","        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n","        BatchNormalization(),\n","        Conv2D(64, (3, 3), activation='relu'),\n","        BatchNormalization(),\n","        MaxPooling2D(pool_size=(2, 2), strides=2),\n","        Dropout(0.25),\n","\n","        Conv2D(128, (3, 3), activation='relu'),\n","        BatchNormalization(),\n","        MaxPooling2D(pool_size=(2, 2), strides=2),\n","        Dropout(0.25),\n","\n","        Conv2D(256, (3, 3), activation='relu'),\n","        BatchNormalization(),\n","        MaxPooling2D(pool_size=(2, 2), strides=2),\n","        Dropout(0.25),\n","\n","        Flatten(),\n","        Dense(512, activation='relu'),\n","        Dropout(0.5),\n","        Dense(10, activation='softmax')\n","    ])\n","    return model\n"],"metadata":{"id":"fzYfTxI9bmIZ","executionInfo":{"status":"ok","timestamp":1727106514309,"user_tz":-180,"elapsed":2,"user":{"displayName":"Sara Soltani","userId":"00129795583987472913"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["3. آموزش و مقایسه با شبکه Dense:\n","\n","برای آموزش شبکه، از optimizer و loss مناسب استفاده کرده و مدل را روی داده‌های آموزش و اعتبارسنجی به مدت 50 epoch اجرا می‌کنیم."],"metadata":{"id":"p45yF4sobs3R"}},{"cell_type":"code","source":["from tensorflow.keras.optimizers import Adam\n","\n","# ساخت مدل CNN\n","cnn_model = create_cnn_model()\n","\n","# کامپایل مدل\n","cnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# آموزش مدل\n","history_cnn = cnn_model.fit(x_train, y_train, epochs=50, validation_data=(x_val, y_val), batch_size=64, verbose=1)\n","\n","# ارزیابی مدل روی داده‌های تست\n","test_loss, test_accuracy = cnn_model.evaluate(x_test, y_test)\n","print(f\"Test accuracy: {test_accuracy:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DOsz5vPgbueo","executionInfo":{"status":"ok","timestamp":1727106871897,"user_tz":-180,"elapsed":357590,"user":{"displayName":"Sara Soltani","userId":"00129795583987472913"}},"outputId":"f40ec50f-dee3-4025-ef56-c7960feb2d73"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.3482 - loss: 2.0188 - val_accuracy: 0.4535 - val_loss: 1.7326\n","Epoch 2/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5431 - loss: 1.2800 - val_accuracy: 0.6289 - val_loss: 1.0408\n","Epoch 3/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6197 - loss: 1.0719 - val_accuracy: 0.6085 - val_loss: 1.1979\n","Epoch 4/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6718 - loss: 0.9322 - val_accuracy: 0.7069 - val_loss: 0.8267\n","Epoch 5/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7065 - loss: 0.8374 - val_accuracy: 0.6920 - val_loss: 0.9298\n","Epoch 6/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.7269 - loss: 0.7869 - val_accuracy: 0.6577 - val_loss: 1.0861\n","Epoch 7/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7317 - loss: 0.7732 - val_accuracy: 0.7484 - val_loss: 0.7459\n","Epoch 8/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7568 - loss: 0.6944 - val_accuracy: 0.7619 - val_loss: 0.7058\n","Epoch 9/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.7684 - loss: 0.6693 - val_accuracy: 0.7779 - val_loss: 0.6601\n","Epoch 10/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7807 - loss: 0.6357 - val_accuracy: 0.7677 - val_loss: 0.6862\n","Epoch 11/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.7930 - loss: 0.5937 - val_accuracy: 0.7652 - val_loss: 0.7133\n","Epoch 12/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7967 - loss: 0.5787 - val_accuracy: 0.7691 - val_loss: 0.7134\n","Epoch 13/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8137 - loss: 0.5330 - val_accuracy: 0.7863 - val_loss: 0.6728\n","Epoch 14/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8140 - loss: 0.5306 - val_accuracy: 0.7779 - val_loss: 0.7111\n","Epoch 15/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8175 - loss: 0.5262 - val_accuracy: 0.8047 - val_loss: 0.5952\n","Epoch 16/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8306 - loss: 0.4872 - val_accuracy: 0.7860 - val_loss: 0.6926\n","Epoch 17/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8403 - loss: 0.4657 - val_accuracy: 0.7847 - val_loss: 0.7145\n","Epoch 18/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8375 - loss: 0.4754 - val_accuracy: 0.8051 - val_loss: 0.6063\n","Epoch 19/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8449 - loss: 0.4386 - val_accuracy: 0.8119 - val_loss: 0.5962\n","Epoch 20/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8528 - loss: 0.4261 - val_accuracy: 0.8172 - val_loss: 0.5983\n","Epoch 21/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8529 - loss: 0.4220 - val_accuracy: 0.8029 - val_loss: 0.6677\n","Epoch 22/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8545 - loss: 0.4124 - val_accuracy: 0.8056 - val_loss: 0.6248\n","Epoch 23/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8629 - loss: 0.3970 - val_accuracy: 0.8085 - val_loss: 0.6222\n","Epoch 24/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8663 - loss: 0.3814 - val_accuracy: 0.8187 - val_loss: 0.5988\n","Epoch 25/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8652 - loss: 0.3884 - val_accuracy: 0.8193 - val_loss: 0.6065\n","Epoch 26/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8731 - loss: 0.3595 - val_accuracy: 0.8183 - val_loss: 0.6271\n","Epoch 27/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8724 - loss: 0.3606 - val_accuracy: 0.8267 - val_loss: 0.6019\n","Epoch 28/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8803 - loss: 0.3437 - val_accuracy: 0.8201 - val_loss: 0.6270\n","Epoch 29/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8795 - loss: 0.3467 - val_accuracy: 0.8341 - val_loss: 0.5943\n","Epoch 30/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.8844 - loss: 0.3375 - val_accuracy: 0.8183 - val_loss: 0.6609\n","Epoch 31/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8878 - loss: 0.3250 - val_accuracy: 0.8195 - val_loss: 0.6644\n","Epoch 32/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8908 - loss: 0.3123 - val_accuracy: 0.8192 - val_loss: 0.6687\n","Epoch 33/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8945 - loss: 0.3043 - val_accuracy: 0.8132 - val_loss: 0.6710\n","Epoch 34/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8867 - loss: 0.3224 - val_accuracy: 0.8309 - val_loss: 0.5964\n","Epoch 35/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8837 - loss: 0.3399 - val_accuracy: 0.8331 - val_loss: 0.6097\n","Epoch 36/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8980 - loss: 0.2990 - val_accuracy: 0.8351 - val_loss: 0.5897\n","Epoch 37/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9037 - loss: 0.2822 - val_accuracy: 0.8301 - val_loss: 0.6156\n","Epoch 38/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8978 - loss: 0.2845 - val_accuracy: 0.8329 - val_loss: 0.5889\n","Epoch 39/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9027 - loss: 0.2780 - val_accuracy: 0.8345 - val_loss: 0.6243\n","Epoch 40/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8975 - loss: 0.2964 - val_accuracy: 0.8235 - val_loss: 0.6813\n","Epoch 41/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9012 - loss: 0.2865 - val_accuracy: 0.8335 - val_loss: 0.6156\n","Epoch 42/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9118 - loss: 0.2555 - val_accuracy: 0.8264 - val_loss: 0.6485\n","Epoch 43/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9066 - loss: 0.2668 - val_accuracy: 0.8323 - val_loss: 0.6448\n","Epoch 44/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9142 - loss: 0.2589 - val_accuracy: 0.8271 - val_loss: 0.6219\n","Epoch 45/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9074 - loss: 0.2729 - val_accuracy: 0.8080 - val_loss: 0.7276\n","Epoch 46/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9111 - loss: 0.2611 - val_accuracy: 0.8355 - val_loss: 0.6173\n","Epoch 47/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9133 - loss: 0.2540 - val_accuracy: 0.8272 - val_loss: 0.6683\n","Epoch 48/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9131 - loss: 0.2494 - val_accuracy: 0.8284 - val_loss: 0.6402\n","Epoch 49/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9180 - loss: 0.2400 - val_accuracy: 0.8349 - val_loss: 0.5861\n","Epoch 50/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9188 - loss: 0.2445 - val_accuracy: 0.8399 - val_loss: 0.5907\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8449 - loss: 0.5815\n","Test accuracy: 0.8430\n"]}]},{"cell_type":"markdown","source":["4. استفاده از برنامه‌های زمانی Exponential و OneCycle:\n","\n","برای مقایسه این دو برنامه زمانی (learning rate schedules)، ابتدا مدل‌ها را با استفاده از هر کدام از این روش‌ها آموزش داده و سپس مقایسه می‌کنیم.\n","\n","Exponential Decay:"],"metadata":{"id":"ag8h_9Klbz8D"}},{"cell_type":"code","source":["from tensorflow.keras.callbacks import LearningRateScheduler\n","\n","# تابع برنامه زمانی Exponential Decay\n","def exponential_decay(epoch, lr):\n","    return lr * 0.96 ** epoch\n","\n","# آموزش مدل با Exponential Decay\n","exp_decay_schedule = LearningRateScheduler(exponential_decay)\n","history_exp_decay = cnn_model.fit(x_train, y_train, epochs=50, validation_data=(x_val, y_val), callbacks=[exp_decay_schedule], batch_size=64, verbose=1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KeOmfn6sb2H_","executionInfo":{"status":"ok","timestamp":1727107255054,"user_tz":-180,"elapsed":383165,"user":{"displayName":"Sara Soltani","userId":"00129795583987472913"}},"outputId":"c9b7382f-77fa-491b-9f39-6a8d84de2863"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9219 - loss: 0.2294 - val_accuracy: 0.8383 - val_loss: 0.6492 - learning_rate: 0.0010\n","Epoch 2/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9220 - loss: 0.2206 - val_accuracy: 0.8213 - val_loss: 0.7019 - learning_rate: 9.6000e-04\n","Epoch 3/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9264 - loss: 0.2183 - val_accuracy: 0.8303 - val_loss: 0.6525 - learning_rate: 8.8474e-04\n","Epoch 4/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9270 - loss: 0.2123 - val_accuracy: 0.8389 - val_loss: 0.6397 - learning_rate: 7.8276e-04\n","Epoch 5/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9294 - loss: 0.2036 - val_accuracy: 0.8485 - val_loss: 0.6177 - learning_rate: 6.6483e-04\n","Epoch 6/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9362 - loss: 0.1835 - val_accuracy: 0.8457 - val_loss: 0.6143 - learning_rate: 5.4209e-04\n","Epoch 7/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9423 - loss: 0.1671 - val_accuracy: 0.8509 - val_loss: 0.6133 - learning_rate: 4.2432e-04\n","Epoch 8/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.1608 - val_accuracy: 0.8535 - val_loss: 0.6030 - learning_rate: 3.1886e-04\n","Epoch 9/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9485 - loss: 0.1477 - val_accuracy: 0.8516 - val_loss: 0.6249 - learning_rate: 2.3002e-04\n","Epoch 10/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9513 - loss: 0.1431 - val_accuracy: 0.8523 - val_loss: 0.6243 - learning_rate: 1.5930e-04\n","Epoch 11/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9513 - loss: 0.1412 - val_accuracy: 0.8503 - val_loss: 0.6246 - learning_rate: 1.0591e-04\n","Epoch 12/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9533 - loss: 0.1399 - val_accuracy: 0.8507 - val_loss: 0.6255 - learning_rate: 6.7593e-05\n","Epoch 13/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9544 - loss: 0.1334 - val_accuracy: 0.8536 - val_loss: 0.6213 - learning_rate: 4.1415e-05\n","Epoch 14/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9547 - loss: 0.1294 - val_accuracy: 0.8527 - val_loss: 0.6251 - learning_rate: 2.4360e-05\n","Epoch 15/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9544 - loss: 0.1307 - val_accuracy: 0.8521 - val_loss: 0.6228 - learning_rate: 1.3756e-05\n","Epoch 16/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9555 - loss: 0.1313 - val_accuracy: 0.8540 - val_loss: 0.6175 - learning_rate: 7.4567e-06\n","Epoch 17/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9559 - loss: 0.1296 - val_accuracy: 0.8539 - val_loss: 0.6200 - learning_rate: 3.8805e-06\n","Epoch 18/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9557 - loss: 0.1282 - val_accuracy: 0.8528 - val_loss: 0.6219 - learning_rate: 1.9386e-06\n","Epoch 19/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9547 - loss: 0.1275 - val_accuracy: 0.8533 - val_loss: 0.6205 - learning_rate: 9.2978e-07\n","Epoch 20/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9579 - loss: 0.1209 - val_accuracy: 0.8540 - val_loss: 0.6205 - learning_rate: 4.2809e-07\n","Epoch 21/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9555 - loss: 0.1278 - val_accuracy: 0.8545 - val_loss: 0.6176 - learning_rate: 1.8922e-07\n","Epoch 22/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9538 - loss: 0.1340 - val_accuracy: 0.8533 - val_loss: 0.6215 - learning_rate: 8.0289e-08\n","Epoch 23/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9543 - loss: 0.1309 - val_accuracy: 0.8532 - val_loss: 0.6201 - learning_rate: 3.2706e-08\n","Epoch 24/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9556 - loss: 0.1291 - val_accuracy: 0.8536 - val_loss: 0.6202 - learning_rate: 1.2790e-08\n","Epoch 25/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9563 - loss: 0.1288 - val_accuracy: 0.8536 - val_loss: 0.6202 - learning_rate: 4.8014e-09\n","Epoch 26/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9556 - loss: 0.1269 - val_accuracy: 0.8535 - val_loss: 0.6191 - learning_rate: 1.7304e-09\n","Epoch 27/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9536 - loss: 0.1366 - val_accuracy: 0.8540 - val_loss: 0.6183 - learning_rate: 5.9869e-10\n","Epoch 28/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9533 - loss: 0.1311 - val_accuracy: 0.8533 - val_loss: 0.6205 - learning_rate: 1.9885e-10\n","Epoch 29/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9544 - loss: 0.1294 - val_accuracy: 0.8523 - val_loss: 0.6208 - learning_rate: 6.3405e-11\n","Epoch 30/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9572 - loss: 0.1298 - val_accuracy: 0.8536 - val_loss: 0.6208 - learning_rate: 1.9408e-11\n","Epoch 31/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9546 - loss: 0.1319 - val_accuracy: 0.8536 - val_loss: 0.6197 - learning_rate: 5.7033e-12\n","Epoch 32/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9540 - loss: 0.1310 - val_accuracy: 0.8528 - val_loss: 0.6208 - learning_rate: 1.6089e-12\n","Epoch 33/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9544 - loss: 0.1289 - val_accuracy: 0.8528 - val_loss: 0.6227 - learning_rate: 4.3572e-13\n","Epoch 34/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9564 - loss: 0.1294 - val_accuracy: 0.8544 - val_loss: 0.6182 - learning_rate: 1.1328e-13\n","Epoch 35/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9545 - loss: 0.1278 - val_accuracy: 0.8525 - val_loss: 0.6216 - learning_rate: 2.8274e-14\n","Epoch 36/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9583 - loss: 0.1228 - val_accuracy: 0.8540 - val_loss: 0.6191 - learning_rate: 6.7745e-15\n","Epoch 37/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9556 - loss: 0.1239 - val_accuracy: 0.8532 - val_loss: 0.6194 - learning_rate: 1.5583e-15\n","Epoch 38/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9555 - loss: 0.1296 - val_accuracy: 0.8523 - val_loss: 0.6208 - learning_rate: 3.4409e-16\n","Epoch 39/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9514 - loss: 0.1393 - val_accuracy: 0.8537 - val_loss: 0.6196 - learning_rate: 7.2943e-17\n","Epoch 40/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9537 - loss: 0.1340 - val_accuracy: 0.8536 - val_loss: 0.6209 - learning_rate: 1.4844e-17\n","Epoch 41/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9548 - loss: 0.1257 - val_accuracy: 0.8539 - val_loss: 0.6194 - learning_rate: 2.9001e-18\n","Epoch 42/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9537 - loss: 0.1354 - val_accuracy: 0.8533 - val_loss: 0.6221 - learning_rate: 5.4392e-19\n","Epoch 43/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9527 - loss: 0.1377 - val_accuracy: 0.8536 - val_loss: 0.6205 - learning_rate: 9.7932e-20\n","Epoch 44/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9564 - loss: 0.1272 - val_accuracy: 0.8540 - val_loss: 0.6191 - learning_rate: 1.6927e-20\n","Epoch 45/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9544 - loss: 0.1305 - val_accuracy: 0.8531 - val_loss: 0.6211 - learning_rate: 2.8088e-21\n","Epoch 46/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9552 - loss: 0.1317 - val_accuracy: 0.8532 - val_loss: 0.6207 - learning_rate: 4.4743e-22\n","Epoch 47/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9548 - loss: 0.1318 - val_accuracy: 0.8533 - val_loss: 0.6217 - learning_rate: 6.8423e-23\n","Epoch 48/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9538 - loss: 0.1317 - val_accuracy: 0.8528 - val_loss: 0.6216 - learning_rate: 1.0045e-23\n","Epoch 49/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9545 - loss: 0.1291 - val_accuracy: 0.8532 - val_loss: 0.6209 - learning_rate: 1.4157e-24\n","Epoch 50/50\n","\u001b[1m665/665\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9538 - loss: 0.1342 - val_accuracy: 0.8536 - val_loss: 0.6190 - learning_rate: 1.9154e-25\n"]}]},{"cell_type":"markdown","source":["OneCycle:"],"metadata":{"id":"vXjyIqc0b6Cw"}},{"cell_type":"code","source":["from tensorflow.keras.optimizers.schedules import OneCycleLR\n","\n","# برنامه زمانی OneCycle\n","one_cycle_schedule = OneCycleLR(max_lr=0.01, total_steps=50*len(x_train)//64)\n","optimizer_onecycle = Adam(learning_rate=one_cycle_schedule)\n","\n","cnn_model.compile(optimizer=optimizer_onecycle, loss='categorical_crossentropy', metrics=['accuracy'])\n","history_onecycle = cnn_model.fit(x_train, y_train, epochs=50, validation_data=(x_val, y_val), batch_size=64, verbose=1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"id":"RsW7Av7Yb6uZ","executionInfo":{"status":"error","timestamp":1727107255055,"user_tz":-180,"elapsed":27,"user":{"displayName":"Sara Soltani","userId":"00129795583987472913"}},"outputId":"4673aa3d-d52b-4878-ccb8-a6e4ddea4eff"},"execution_count":5,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'OneCycleLR' from 'tensorflow.keras.optimizers.schedules' (/usr/local/lib/python3.10/dist-packages/keras/_tf_keras/keras/optimizers/schedules/__init__.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-f989dfa91fee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneCycleLR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# برنامه زمانی OneCycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mone_cycle_schedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneCycleLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer_onecycle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_cycle_schedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'OneCycleLR' from 'tensorflow.keras.optimizers.schedules' (/usr/local/lib/python3.10/dist-packages/keras/_tf_keras/keras/optimizers/schedules/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["5. اثر Pooling و بررسی Strideها:\n","\n","برای بررسی اثر لایه‌های Pooling و همچنین مقایسه strideهای مختلف، دو مدل با و بدون لایه‌های Pooling آموزش می‌دهیم و سپس نتایج را مقایسه می‌کنیم.\n","\n","مدل بدون لایه Pooling:"],"metadata":{"id":"SyxWEl-Nb-lq"}},{"cell_type":"code","source":["def create_cnn_without_pooling():\n","    model = Sequential([\n","        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n","        BatchNormalization(),\n","        Conv2D(64, (3, 3), activation='relu'),\n","        BatchNormalization(),\n","        Dropout(0.25),\n","\n","        Conv2D(128, (3, 3), activation='relu'),\n","        BatchNormalization(),\n","        Dropout(0.25),\n","\n","        Conv2D(256, (3, 3), activation='relu'),\n","        BatchNormalization(),\n","        Dropout(0.25),\n","\n","        Flatten(),\n","        Dense(512, activation='relu'),\n","        Dropout(0.5),\n","        Dense(10, activation='softmax')\n","    ])\n","    return model\n"],"metadata":{"id":"xSPsIHw4cCCY","executionInfo":{"status":"aborted","timestamp":1727107255055,"user_tz":-180,"elapsed":22,"user":{"displayName":"Sara Soltani","userId":"00129795583987472913"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["مدل با Strideهای مختلف:"],"metadata":{"id":"HYykCWy_cH6E"}},{"cell_type":"code","source":["def create_cnn_with_stride(stride_value):\n","    model = Sequential([\n","        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n","        BatchNormalization(),\n","        Conv2D(64, (3, 3), activation='relu'),\n","        BatchNormalization(),\n","        MaxPooling2D(pool_size=(2, 2), strides=stride_value),\n","        Dropout(0.25),\n","\n","        Conv2D(128, (3, 3), activation='relu'),\n","        BatchNormalization(),\n","        MaxPooling2D(pool_size=(2, 2), strides=stride_value),\n","        Dropout(0.25),\n","\n","        Conv2D(256, (3, 3), activation='relu'),\n","        BatchNormalization(),\n","        MaxPooling2D(pool_size=(2, 2), strides=stride_value),\n","        Dropout(0.25),\n","\n","        Flatten(),\n","        Dense(512, activation='relu'),\n","        Dropout(0.5),\n","        Dense(10, activation='softmax')\n","    ])\n","    return model\n"],"metadata":{"id":"KG7Hq5arcIgX","executionInfo":{"status":"aborted","timestamp":1727107255055,"user_tz":-180,"elapsed":21,"user":{"displayName":"Sara Soltani","userId":"00129795583987472913"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["6. مقایسه و نمایش نتایج:\n","\n","برای مقایسه عملکرد مدل‌ها، دقت و زیان آن‌ها را برای هر نوع تنظیمات روی داده‌های تست رسم می‌کنیم."],"metadata":{"id":"7tbj04DmcMsZ"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def plot_history(histories, key='accuracy'):\n","    plt.figure(figsize=(10,8))\n","\n","    for name, history in histories:\n","        plt.plot(history.history[key], label=name)\n","\n","    plt.title(f'Model {key}')\n","    plt.xlabel('Epochs')\n","    plt.ylabel(key)\n","    plt.legend()\n","    plt.show()\n","\n","# رسم گراف‌های مقایسه‌ای دقت و زیان\n","plot_history([('CNN', history_cnn), ('Exponential Decay', history_exp_decay), ('OneCycle', history_onecycle)], key='val_accuracy')\n","plot_history([('CNN', history_cnn), ('Exponential Decay', history_exp_decay), ('OneCycle', history_onecycle)], key='val_loss')\n"],"metadata":{"id":"9ZoptiK6cVEQ","executionInfo":{"status":"aborted","timestamp":1727107255055,"user_tz":-180,"elapsed":21,"user":{"displayName":"Sara Soltani","userId":"00129795583987472913"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7. نتیجه‌گیری:\n","\n","مدت زمان آموزش: زمان آموزش شبکه CNN باید با شبکه Dense مقایسه شود. معمولاً شبکه‌های کانولوشنال زمان بیشتری برای آموزش نیاز دارند، اما دقت بالاتری را روی داده‌های تصویر به دست می‌آورند.\n","\n","دقت پیش‌بینی: دقت پیش‌بینی شبکه CNN با لایه‌های کانولوشن به طور معمول بهتر از شبکه Dense خواهد بود، چرا که شبکه‌های کانولوشنال به خوبی می‌توانند ویژگی‌های مکانی داده‌های تصویری را استخراج کنند.\n","\n","اثر Pooling و Stride: لایه‌های Pooling و همچنین مقدار stride در Pooling می‌تواند به کاهش زمان محاسباتی و بهبود دقت مدل کمک کند."],"metadata":{"id":"I7lndepHcYLh"}}]}